### Question 5.1  
Using crime data from the file uscrime.txt (http://www.statsci.org/data/general/uscrime.txt, description at http://www.statsci.org/data/general/uscrime.html), test to see whether there are any outliers in the last column (number of crimes per 100,000 people).  Use the grubbs.test function in the outliers package in R    


```{r}
# Let's clear environment and get the packages we are going to use
rm(list = ls())
library(outliers)

```

```{r}
# Read data & look at last column 
data <- read.table('uscrime.txt', header = T)
head(data)
```

```{r}
#quickly view the data in last column using boxplot 
boxplot(data$Crime, main = 'Boxplot distribution of number of crimes')

```
  
#### *we notice there are data points on top of the chart outside box whiskers. Indicating we could try to use Type=10 to test if the max value is outlier * 
```{r}
# load package 
grubbs.test(data$Crime, type=10)
```

#### *Since P value is not less than 0.05 (generally α=0.05), we fail to reject the null hypothesis. We don't have sufficient evidence to say 1993 is an outlier.   Now, let's also try Type=11 to test two opposite outliers.* 

```{r}
grubbs.test(data$Crime, type=11)

```
#### *The highest value is 1993 and the lowest value is 342, Since P value is not less than 0.05 (generally α=0.05), we fail to reject the null hypothesis. We do not have sufficient evidence to say that these data points are outlier.*  
  
#### *Since the boxplot is showing 2 dots that seems to be outliers, we should aloso try to set Type=20. But in our data, we have more than 30 values which means we couldn't use Type=20. (we will get an error if we try to run.)*

### Question 6.1  
Describe a situation or problem from your job, everyday life, current events, etc., for which a Change Detection model would be appropriate. Applying the CUSUM technique, how would you choose the critical value and the threshold?  

- Answer:  
Engineer team in company handle backend data processing. One of the steps is receiving data from third party data vendor. Sometimes the ETL process works smoothly sometimes not.If data processing time has significant delay, this will causing errors and result in cost of production time to fix errors. So our engineer want to be alerted so that be able to proactive monitoring before there is actual task fail.In this case, a change of decetion model would be appropriate. To implement the CUSUM method, we can monitor significant changes by using mean ETL time as our threshold, we could also starting by setting critical value to 10 seconds just so have a room for reasonable fluctuate. 
  
    
### Question 6.2.1  
Using July through October daily-high-temperature data for Atlanta for 1996 through 2015, use a CUSUM approach to identify when unofficial summer ends (i.e., when the weather starts cooling off) each year.  You can get the data that you need from the file temps.txt or online, for example at http://www.iweathernet.com/atlanta-weather-records  or https://www.wunderground.com/history/airport/KFTY/2015/7/1/CustomHistory.html .  You can use R if you’d like, but it’s straightforward enough that an Excel spreadsheet can easily do the job too.  

#### Steps:  
1.Find daily average temperature over this period 1996-2015   
2.Calculated the mean of the Average temperature and standard deviation for the month of July (the 'Summer'), which is the *Jul_avg* and *Jul_sd* down below  
3.export dataframe to csv file.  
4.Implement CUSUM in EXCEL (PLease refer to - 'daily_avg.csv')  

```{r}
# Read data 
temp <- read.table('temps.txt', header = T)
head(temp)

```

```{r}
# Starting by temperature for each day across the years
daily_avg <- rowMeans(temp[, -1])
df <- data.frame(date=temp$DAY, daily_avg)
x <- as.Date(df$date, '%d-%b')
df$date <- format(x, format = '%m/%d')
head(df)

#get July average temperature
jul <- df[1:31,]
Jul_avg <- mean(jul[,-1])
Jul_sd <- sd(jul[,-1])

```


```{r}
# Export dataframe to EXCEL
write.csv(df, 'daily_avg.csv', row.names = F)
```


```{r}
library('readxl')
df <- read_excel('daily_avg.xls', sheet = 'data')
plot(df, main = 'Average temperature Jul - Oct')
```
  
#### *As we can see in the EXCEL, I'm using 5(Jul_sd) for T value and 0.5(Jul_sd) for C value. Then put into the MAX function to find the Change of St. We can see that starting from End of August, 08/30 for example, indicating the ending of the summer and weather start cooling down in Atlanta.(please refer to EXCEL 'daily_avg.xls')*
  
  
### Question 6.2.2  
Use a CUSUM approach to make a judgment of whether Atlanta’s summer climate has gotten warmer in that time (and if so, when).  

#### Steps:  
To define if Atlanta's summer climate has gotten warmer, let's take a look at if the cooling off date each year and temperature is changing.  
1.Find July mean temperature and sd for each year (this is in R)  
2.Find cooling off date each year (In EXCEL)  
3.Find out how long is that summer (In EXCEL)  
4.Implement CUSUM detect changing (In EXCEL)  

```{r}
# Get mean temperature of July for each year
July <- temp[1:31, 2:ncol(temp) ]
july_mean <- colMeans(July)
#Get Sd of July for each year
july_sd <- sapply(July, sd, na.rm = TRUE)

```

```{r}
july_stats <- rbind(july_mean, july_sd)
write.csv(july_stats, 'July_stats.csv', row.names = F)
```

```{r}
library('readxl')
result <- read_excel('July_stats.xls', sheet = 'Transpose')
result <- result[1:21,]
names(result)[names(result)=='# of Days detect change'] <- 'Days'
result


```
```{r}
plot(result$YEAR, result$St, type = "b", pch = 19)
abline(h=38, col='purple')
```


#### *Summary:  By implement the detect increase using Atlanta Daily high temperature data, we first find out the July temperature mean of each year and use the mean and standard deviation and CUSUM find out unofficial summer ends of each year between 1996 and 2015. Then we calculated the days between July 1st to the unofficial cooling off date for each year. Next we use CUSUM again to detect changing for the days between 1996 and 2015. As we can see from the data, 2007 has been detect changing. According to the graph above, purple line is the threshold and the dot above is 2007.(please refer to EXCEL 'July_stats.xls')*
